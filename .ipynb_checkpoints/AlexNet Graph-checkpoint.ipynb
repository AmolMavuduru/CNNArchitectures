{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Graph Implementation in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs, Placeholders, and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "IMAGE_WIDTH = 201\n",
    "IMAGE_HEIGHT = 201\n",
    "x = tf.placeholder(tf.float32, shape=[None,IMAGE_WIDTH,IMAGE_HEIGHT,3]) # represents input 227 x 227 image with 3 color channels (RGB)\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "training = tf.placeholder(tf.bool) # Used for batch normalization - a boolean to indicate whether or not we are training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):  # initializes the weights randomly with a normal distribution\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape): # inditializes the bias term as a constant of 0.1 values\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def max_pool_nbyn(x, name, filter_size=2, stride=2, pad=True):   # creates a max pooling layer\n",
    "    if pad:\n",
    "        return tf.nn.max_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "    else:\n",
    "        return tf.nn.max_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='VALID', name=name)\n",
    "\n",
    "\n",
    "def normal_full_layer(input_layer, size):   # creates the fully connected layer\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b  # simple forward propagation using matrix multiplication\n",
    "\n",
    "def batch_normalization(input_layer, training):  # function for batch normalization\n",
    "    \n",
    "    return tf.layers.batch_normalization(input_layer, training=training)\n",
    "\n",
    "def local_response_normalization(input_layer, radius, alpha, beta, name, bias=1.0): # function for local response normalization\n",
    "    \n",
    "     return tf.nn.local_response_normalization(x, depth_radius=radius,\n",
    "                                              alpha=alpha, beta=beta,\n",
    "                                              bias=bias, name=name)\n",
    "\n",
    "\n",
    "def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name, pad=None, add_relu=True):\n",
    "    \n",
    "    kernel_shape = [filter_height, filter_width]\n",
    "    #init_random_dist = tf.truncated_normal(kernel_shape, stddev=0.1)\n",
    "    if pad is not None:\n",
    "        padded_x = tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]])\n",
    "        if add_relu:\n",
    "            return tf.layers.conv2d(padded_x, filters=num_filters, \n",
    "                            kernel_size=(filter_width, filter_height),\n",
    "                            strides=(stride_x, stride_y),\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            use_bias=True, bias_initializer=tf.constant_initializer(0.1), \n",
    "                            activation = tf.nn.relu, name=name)\n",
    "        else:\n",
    "            return tf.layers.conv2d(padded_x, filters=num_filters, \n",
    "                            kernel_size=(filter_width, filter_height),\n",
    "                            strides=(stride_x, stride_y),\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            use_bias=True, bias_initializer=tf.constant_initializer(0.1), \n",
    "                            activation = None, name=name)\n",
    "            \n",
    "    else:\n",
    "        if add_relu:\n",
    "            return tf.layers.conv2d(x, filters=num_filters, \n",
    "                            kernel_size=(filter_width, filter_height),\n",
    "                            strides=(stride_x, stride_y),\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            use_bias=True, bias_initializer=tf.constant_initializer(0.1), \n",
    "                            activation = tf.nn.relu, name=name)\n",
    "        else:\n",
    "            return tf.layers.conv2d(x, filters=num_filters, \n",
    "                            kernel_size=(filter_width, filter_height),\n",
    "                            strides=(stride_x, stride_y),\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            use_bias=True, bias_initializer=tf.constant_initializer(0.1), \n",
    "                            activation = None, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 1: 96 11 x 11 filters with stride = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(48), Dimension(48), Dimension(96)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1 = conv(x, 11, 11, 96, 4, 4, name='conv_1')\n",
    "conv_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 1: 3 x 3 filters with stride =  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(23), Dimension(23), Dimension(96)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_1 = max_pool_nbyn(conv_1, filter_size=3, stride=2, pad=False, name='pool_1')\n",
    "pool_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORM 1: Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(23), Dimension(23), Dimension(96)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_1 = batch_normalization(pool_1, training=training)\n",
    "norm_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 2: 256 5 x 5 filters with stride = 1, pad = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(23), Dimension(23), Dimension(256)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_2 = conv(norm_1, 5, 5, 256, 1, 1, pad=2, name='conv_2')\n",
    "conv_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 2: 3 x 3 filters with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(11), Dimension(11), Dimension(256)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_2 = max_pool_nbyn(conv_2, filter_size=3, stride=2, pad=False, name='pool_2')\n",
    "pool_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORM 2: Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(11), Dimension(11), Dimension(256)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_2 = batch_normalization(pool_2, training=training)\n",
    "norm_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 3: 384 3 x 3 filters with stride = 1, pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(11), Dimension(11), Dimension(384)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3 = conv(norm_2, 3, 3, 384, 1, 1, pad=1, name='conv_3')\n",
    "conv_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 4: 384 3 x 3 filters with stride = 1, pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(11), Dimension(11), Dimension(384)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_4 = conv(conv_3, 3, 3, 384, 1, 1, pad=1, name='conv_4')\n",
    "conv_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 5: 256 3 x 3 filters with stride = 1, pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(11), Dimension(11), Dimension(256)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_5 = conv(conv_4, 3, 3, 256, 1, 1, pad=1, name='conv_5')\n",
    "conv_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 3: 3 x 3 filters with stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(5), Dimension(5), Dimension(256)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_3 = max_pool_nbyn(conv_5, filter_size=3, stride=2, pad=False, name='pool_3')\n",
    "pool_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC 6: Fully Connected Layer with 3200 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(3200)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_3_flattened = tf.reshape(pool_3, [-1, 5*5*256])\n",
    "fc_6 = tf.nn.relu(normal_full_layer(pool_3_flattened, 3200))\n",
    "fc_6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC 7: Fully Connected Layer with 3200 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(3200)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_7 = tf.nn.relu(normal_full_layer(fc_6, 3200))\n",
    "fc_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC 8: Final Fully Connected Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_8 = normal_full_layer(fc_7, NUM_CLASSES)\n",
    "fc_8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = fc_8\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-3e2eceb240c6>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([[ -3.87687617e+04,   5.78726172e+04],\n",
    " [ -8.46322708e+01,  -1.57727783e+04],\n",
    " [  3.12215157e+01,  -1.54957100e+04],\n",
    " [  1.07811012e+02,  -1.59461592e+04],\n",
    " [ -6.13127556e+01,  -1.57387754e+04],\n",
    " [ -3.89429531e+04,   5.78887539e+04],\n",
    " [ -3.90034453e+04,   5.85213750e+04],\n",
    " [ -1.66022705e+02,  -1.58228965e+04],\n",
    " [ -3.86717590e+02,  -1.58087080e+04],\n",
    " [  2.07964935e+02,  -1.60525752e+04],\n",
    " [ -3.92422031e+04,   5.79715508e+04],\n",
    " [ -3.88493008e+04,   5.79881914e+04],\n",
    " [ -3.97632930e+04,   5.85155039e+04],\n",
    " [ -3.89650117e+04,   5.75835781e+04],\n",
    " [ -3.91298594e+04,   5.78670352e+04],\n",
    " [ -3.88932773e+04,   5.78557070e+04],\n",
    " [ -3.93219719e+01,  -1.58440771e+04],\n",
    " [ -1.54317963e+02,  -1.59467764e+04],\n",
    " [ -3.91408672e+04,   5.83769883e+04],\n",
    " [ -3.91114141e+04,   5.77723203e+04],\n",
    " [ -5.24858704e+01,  -1.58276045e+04],\n",
    " [ -3.88121562e+04,   5.77825625e+04],\n",
    " [ -3.91034258e+04,   5.84947461e+04],\n",
    " [ -3.95017539e+04,   5.80816758e+04],\n",
    " [ -3.90695508e+04,   5.80305508e+04]])\n",
    "\n",
    "true = np.array([[ 0.,  1.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 1.,  0.],\n",
    " [ 1.,  0.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 1.,  0.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.],\n",
    " [ 0.,  1.]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={y_true:true, y_pred:pred}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001) # Adam optimizer\n",
    "train = optimizer.minimize(cross_entropy)  # training operation\n",
    "\n",
    "init = tf.global_variables_initializer() # global variables initializer"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
