{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet Implementation in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs, Placeholders, and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMAGE_WIDTH = 224   # Image width for original GoogLeNet architecture for the ImageNet Challenge\n",
    "IMAGE_HEIGHT = 224  # Image width for the original GoogLeNet architecture for the ImageNet Challenge\n",
    "x = tf.placeholder(tf.float32, shape=[None,IMAGE_WIDTH,IMAGE_HEIGHT,3]) # represents input 227 x 227 image with 3 color channels (RGB)\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "training = tf.placeholder(tf.bool) # Used for batch normalization - a boolean to indicate whether or not we are training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):  # initializes the weights randomly with a normal distribution\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape): # initializes the bias term as a constant of 0.1 values\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W, pad=True, strides=[1,1,1,1]): # creates a 2D convolution with or without padding\n",
    "    if pad:\n",
    "        return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "    else:\n",
    "        return tf.nn.conv2d(x, W, strides=strides, padding='VALID')\n",
    "\n",
    "def max_pool_nbyn(x, name, filter_size=2, stride=2, pad=True):   # creates a max pooling layer\n",
    "    if pad:\n",
    "        return tf.nn.max_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "    else:\n",
    "        return tf.nn.max_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='VALID', name=name)\n",
    "def average_pool_nbyn(x, name, filter_size=2, stride=2, pad=True):   # creates a max pooling layer\n",
    "    if pad:\n",
    "        return tf.nn.avg_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "    else:\n",
    "        return tf.nn.avg_pool(x, ksize=[1, filter_size, filter_size, 1],\n",
    "                          strides=[1, stride, stride, 1], padding='VALID', name=name)\n",
    "\n",
    "def convolutional_layer(input_x, shape, strides=[1,1,1,1]):  # creates the convolutional layer including the weights and biases\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W, strides) + b) # applies a Rectified Linear Unit (ReLU) activation function\n",
    "\n",
    "def normal_full_layer(input_layer, size):   # creates the fully connected layer\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b  # simple forward propagation using matrix multiplication\n",
    "\n",
    "def batch_normalization(input_layer, training):  # function for batch normalization\n",
    "    \n",
    "    return tf.layers.batch_normalization(input_layer, training=training)\n",
    "\n",
    "def local_response_normalization(input_layer, radius, alpha, beta, name, bias=1.0): # function for local response normalization\n",
    "    \n",
    "     return tf.nn.local_response_normalization(x, depth_radius=radius,\n",
    "                                              alpha=alpha, beta=beta,\n",
    "                                              bias=bias, name=name)\n",
    "\n",
    "\n",
    "def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,  # Better function for conv layers\n",
    "         padding='SAME', groups=1):\n",
    "    \"\"\"Create a convolution layer.\n",
    "    Adapted from: https://github.com/ethereon/caffe-tensorflow\n",
    "    \"\"\"\n",
    "    # Get number of input channels\n",
    "    input_channels = int(x.get_shape()[-1])\n",
    "\n",
    "    # Create lambda function for the convolution\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k,\n",
    "                                         strides=[1, stride_y, stride_x, 1],\n",
    "                                         padding=padding)\n",
    "\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # Create tf variables for the weights and biases of the conv layer\n",
    "        weights = tf.get_variable('weights', shape=[filter_height,\n",
    "                                                    filter_width,\n",
    "                                                    input_channels/groups,\n",
    "                                                    num_filters])\n",
    "        biases = tf.get_variable('biases', shape=[num_filters])\n",
    "\n",
    "    if groups == 1:\n",
    "        conv = convolve(x, weights)\n",
    "\n",
    "    # In the cases of multiple groups, split inputs & weights and\n",
    "    else:\n",
    "        # Split input and weights and convolve them separately\n",
    "        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n",
    "        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\n",
    "                                 value=weights)\n",
    "        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n",
    "\n",
    "        # Concat the convolved output together again\n",
    "        conv = tf.concat(axis=3, values=output_groups)\n",
    "\n",
    "    # Add biases\n",
    "    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
    "\n",
    "    # Apply relu function\n",
    "    relu = tf.nn.relu(bias, name=scope.name)\n",
    "\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Generating Inception Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_module(input_layer, conv_1x1_depth, reduce_3x3_depth, conv_3x3_depth, \n",
    "                     reduce_5x5_depth, conv_5x5_depth, pool_proj_depth, name):\n",
    "    # individual 1 x 1 conv layer\n",
    "    conv_1x1 = conv(input_layer, 1, 1, conv_1x1_depth, 1, 1, groups=1, name=(name+'_conv_1x1')) \n",
    "    \n",
    "    # dimensionality reduction with 1 x 1 conv layer before 3 x 3 conv layer\n",
    "    reduce_3x3 = conv(input_layer, 1, 1, reduce_3x3_depth, 1, 1, groups=1, name=(name+'_reduce_3x3')) \n",
    "    \n",
    "    # dimensionality reduction with 1 x 1 conv layer before 5 x 5 conv layer\n",
    "    reduce_5x5 = conv(input_layer, 1, 1, reduce_5x5_depth, 1, 1, groups=1, name=(name+'_reduce_5x5'))\n",
    "    \n",
    "    # 3 x 3 conv layer\n",
    "    conv_3x3 = conv(reduce_3x3, 3, 3, conv_3x3_depth, 1, 1, groups=1, name=(name+'_conv_3x3'))\n",
    "    \n",
    "    # 5 x 5 conv layer\n",
    "    conv_5x5 = conv(reduce_5x5, 5, 5, conv_5x5_depth, 1, 1, groups=1, name=(name+'_conv_5x5'))\n",
    "    \n",
    "    # 3 x 3 max pooling\n",
    "    max_pool = max_pool_nbyn(input_layer, filter_size=3, stride=1, name=(name+'_max_pool'))\n",
    "    \n",
    "    # 1 x 1 convolution on top of pooling\n",
    "    pool_proj = conv(max_pool, 1, 1, pool_proj_depth, 1, 1, groups=1, name=(name+'_pool_proj'))\n",
    "    \n",
    "    # depth-wise concatenation of previous layers to build output\n",
    "    filter_concat = tf.concat([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3)\n",
    "    \n",
    "    return filter_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Generating Auxiliary Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auxiliary_network(input_layer, name, dropout_prob=0.7):\n",
    "    \n",
    "    # 5 x 5 pooling with stride of 3\n",
    "    avg_pool_5x5 = average_pool_nbyn(input_layer, filter_size=5, stride=3, name=(name+'_avg_pool_5x5'))\n",
    "    \n",
    "    # 1 x 1 conv layer with 128 filters for dimensionality reduction\n",
    "    conv_1x1 = conv(avg_pool_5x5, 1, 1, 128, 1, 1, groups=1, name=(name+'_conv_1x1'))\n",
    "    \n",
    "    # Flattened layer\n",
    "    conv_1x1_flattened = tf.reshape(conv_1x1, [-1, (conv_1x1.shape[1]*conv_1x1.shape[2]*conv_1x1.shape[3])])\n",
    "    \n",
    "    # Fully connected layer with 1024 units and ReLU activation\n",
    "    fc = tf.nn.relu(normal_full_layer(conv_1x1_flattened, 1024))\n",
    "    \n",
    "    # dropout layer with default 70% probability of dropout\n",
    "    dropout = tf.nn.dropout(fc, keep_prob=(1-dropout_prob))\n",
    "    \n",
    "    # Linear layer\n",
    "    linear = normal_full_layer(dropout, NUM_CLASSES)\n",
    "    \n",
    "    # Softmax activation for classification output\n",
    "    softmax_output = tf.nn.softmax(linear)\n",
    "    \n",
    "    return softmax_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 1 - 64 7x7 filters with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(112), Dimension(112), Dimension(64)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1 = conv(x, 7, 7, 64, 2, 2, groups=1, name='conv_1')\n",
    "conv_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 1 - 3 x 3 max pooling with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(56), Dimension(56), Dimension(64)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_1 = max_pool_nbyn(conv_1, filter_size=3, stride=2, pad=True, name='pool_1')\n",
    "pool_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV 2 - 192 3 x 3 filters with stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(56), Dimension(56), Dimension(192)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_2 = conv(pool_1, 3, 3, 192, 1, 1, groups=1, name='conv_2')\n",
    "conv_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 2 - 3 x 3 max pooling with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(192)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_2 = max_pool_nbyn(conv_2, filter_size=3, stride=2, pad=True, name='pool_2')\n",
    "pool_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inception 1 - First Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(256)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_1 = inception_module(pool_2, 64, 96, 128, 16, 32, 32, name='inception_1')\n",
    "inception_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 2 - Second Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(480)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_2 = inception_module(inception_1, 128, 128, 192, 32, 96, 64, name='inception_2')\n",
    "inception_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 3 - 3 x 3 max pooling with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(480)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_3 = max_pool_nbyn(inception_2, filter_size=3, stride=2, pad=True, name='pool_3')\n",
    "pool_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 3 - Third Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(512)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_3 = inception_module(pool_3, 192, 96, 208, 16, 48, 64, name='inception_3')\n",
    "inception_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Network 1: Network on the side with softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_0 = auxiliary_network(inception_3, name='aux_network_1')\n",
    "softmax_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 4 - Fourth Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(512)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_4 = inception_module(inception_3, 160, 112, 224, 24, 64, 64, name='inception_4')\n",
    "inception_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 5 - Fifth Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(512)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_5 = inception_module(inception_4, 128, 128, 256, 24, 64, 64, name='inception_5')\n",
    "inception_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 6 - Sixth Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(528)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_6 = inception_module(inception_5, 112, 144, 288, 32, 64, 64, name='inception_6')\n",
    "inception_6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Network 2: Network on the side with softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_1 = auxiliary_network(inception_6, name='aux_network_2')\n",
    "softmax_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 7 - Seventh Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(832)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_7 = inception_module(inception_6, 256, 160, 320, 32, 128, 128, name='inception_7')\n",
    "inception_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL 4 - 3 x 3 max pooling with stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(832)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_4 = max_pool_nbyn(inception_7, filter_size=3, stride=2, pad=True, name='pool_4')\n",
    "pool_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 8 - Eighth Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(832)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_8 = inception_module(pool_4, 256, 160, 320, 32, 128, 128, name='inception_8')\n",
    "inception_8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception 9 - Ninth Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(1024)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_9 = inception_module(inception_8, 384, 192, 384, 48, 128, 128, name='inception_9')\n",
    "inception_9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVG POOL - 7 x 7 average pooling with stride = 1 and no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(1024)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool = average_pool_nbyn(inception_9, filter_size=7, stride=1, pad=False, name='avg_pool')\n",
    "avg_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(1024)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_layer = tf.nn.dropout(avg_pool, keep_prob=hold_prob)\n",
    "dropout_layer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened = tf.reshape(dropout_layer, [-1, 1024])\n",
    "linear_layer = normal_full_layer(flattened, NUM_CLASSES)\n",
    "linear_layer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classification Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(linear_layer)\n",
    "y_pred.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
